{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "super-suspension",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; padding: 10 px;\">\n",
    "    <h2 style=\"margin: 0 0 20px; color: #FFFFFF; line-height: 1\">CS5002: Programming Principles and Practice</h2>\n",
    "    <img src=\"../rsc/logo.png\" alt=\"University Logo\" style=\"width: 80px; height: auto;\"/>\n",
    "</div>\n",
    "                                  <!--  -->\n",
    "<div style=\"display: flex; justify-content: space-between; width: 100%;\">\n",
    "  <span style=\"text-align: left;\">Practical P3: Data analysis and visualisation Python</span>\n",
    "  <span style=\"text-align: right; font-size: 12px;\">Student ID: 200013825</span>\n",
    "</div> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d440feb",
   "metadata": {},
   "source": [
    "#### Introduction \n",
    "This project aims to modularly read, clean and analyze real-world csv data. Below is the introduction on all the modules and major functions that worked together to complete data analysis.\n",
    "\n",
    "`data_mining.py`: This executable python \n",
    "script automates data cleaning process, I used \n",
    "```python\n",
    "invalid_mask = ~data[column].isin(valid_set)\n",
    "```\n",
    "to collect a list of booleans, indicating whether each csv code is admissible. \n",
    "\n",
    "Based on the context of this dataset, it is more efficient to neglect the type of the data when checking consistency, and then convert all data into pandas' categorical type. \n",
    "``` python\n",
    "data[column] = data[column].astype(str)\n",
    "```\n",
    "I have converted all column in the data as string to help the determination of admissibili\n",
    "\n",
    "`data_analysis.py`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448bcd7",
   "metadata": {},
   "source": [
    "#### Problem Encountered\n",
    "\n",
    "##### __1. infinite commit loop__: \n",
    "When I was trying to set up hooks for git to automatically update the gitlog everytime after commit, i accidently created an infinite loop of git commit, below was what I have included in the post-commit* file in .git/hooks:\n",
    "\n",
    "``` python\n",
    "#!/bin/bash\n",
    "git log --oneline  --graph  > gitlog.txt\n",
    "git commit -m 'gitlog.txt is updated with the latest commit history'\n",
    "```\n",
    "and this created redundant git log histroy that are shown in the gitlog.txt\n",
    "\n",
    "I fixed it by deleting the line to commit within post-commit, after i realized that adding commit within post-commit can trigger recursive calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071106c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-keeping",
   "metadata": {},
   "source": [
    "We start with exploring the content of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Scotland_teaching_file_1PCT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.frame.DataFrame'>\n",
       "RangeIndex: 63388 entries, 0 to 63387\n",
       "Data columns (total 17 columns):\n",
       " #   Column                    Non-Null Count  Dtype \n",
       "---  ------                    --------------  ----- \n",
       " 0   Record_Number             63388 non-null  int64 \n",
       " 1   Region                    63388 non-null  object\n",
       " 2   RESIDENCE_TYPE            63388 non-null  object\n",
       " 3   Family_Composition        63388 non-null  object\n",
       " 4   sex                       63388 non-null  int64 \n",
       " 5   age                       63388 non-null  int64 \n",
       " 6   Marital_Status            63388 non-null  int64 \n",
       " 7   student                   63388 non-null  int64 \n",
       " 8   Country_Of_Birth          63388 non-null  int64 \n",
       " 9   health                    63388 non-null  int64 \n",
       " 10  Ethnic_Group              63388 non-null  int64 \n",
       " 11  religion                  63388 non-null  int64 \n",
       " 12  Economic_Activity         63388 non-null  object\n",
       " 13  Occupation                63388 non-null  object\n",
       " 14  industry                  63388 non-null  object\n",
       " 15  Hours_Worked_Per_Week     63388 non-null  object\n",
       " 16  Approximate_Social_Grade  63388 non-null  object\n",
       "dtypes: int64(9), object(8)\n",
       "memory usage: 8.2+ MB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490442e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record_Number: int64\n",
       "Region: object\n",
       "RESIDENCE_TYPE: object\n",
       "Family_Composition: object\n",
       "sex: int64\n",
       "age: int64\n",
       "Marital_Status: int64\n",
       "student: int64\n",
       "Country_Of_Birth: int64\n",
       "health: int64\n",
       "Ethnic_Group: int64\n",
       "religion: int64\n",
       "Economic_Activity: object\n",
       "Occupation: object\n",
       "industry: object\n",
       "Hours_Worked_Per_Week: object\n",
       "Approximate_Social_Grade: object\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for column, dtype in df.dtypes.items():\n",
    "    print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ebd34-daea-47eb-aa72-914eb174c9fb",
   "metadata": {},
   "source": [
    "Next, we read the JSON file with the interpretations of categories. And print all the types of the JSON dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455b3ef-fb85-45f4-80f2-3871170d9483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n",
       "<class 'str'>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"./data/data_dictionary.json\", \"r\") as read_file:\n",
    "    labels = json.load(read_file)\n",
    "\n",
    "for i in labels:\n",
    "    print(type(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
